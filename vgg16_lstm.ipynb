{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudyhendrawn/traditional-dance-video-classification/blob/main/vgg16_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xle_71n0w9B"
      },
      "outputs": [],
      "source": [
        "!rm -rfv sample_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Vm1oly0w9E"
      },
      "source": [
        "### Mounting Repository\n",
        "\n",
        "Mount the repository to get all the data (directories and utilities files) ready to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWjaE8OR0w9G"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/rudyhendrawn/traditional-dance-video-classification.git\n",
        "!mv traditional-dance-video-classification/* .\n",
        "!rm -rfv traditional-dance-video-classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c4IHAhm0w9H"
      },
      "source": [
        "### Mounting Google Drive\n",
        "\n",
        "Google drive need to be setup and mounted to this specific project. Using this code below to setup and mount the google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFED8hD90w9I"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bd7c8a6-0342-409d-b89d-717a94561372"
      },
      "source": [
        "### Initial Setup üßë‚Äçüíª\n",
        "\n",
        "Setup the project, import the required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hk1KR5ic0w9J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import lib.helpers as helpers\n",
        "\n",
        "from lib.keras_video import VideoFrameGenerator\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, LSTM, Dense, Dropout, TimeDistributed\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "from IPython import get_ipython\n",
        "\n",
        "get_ipython().run_line_magic(\"matplotlib\", \"inline\")\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e647c40-bc0d-4af7-8c95-bf0220a1537b"
      },
      "source": [
        "### Pre-Defining Global Variable\n",
        "\n",
        "Setup global variable to use in the entire file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co5s3e620w9K"
      },
      "outputs": [],
      "source": [
        "DS = os.path.sep\n",
        "DATASET_DIR = \"/path/to/your/dataset_drive_dir\" # Change with the correct path to your dataset\n",
        "\n",
        "BATCH_SIZE = 2\n",
        "NB_COLOR_CHANNELS = 3\n",
        "NB_FRAMES = 30\n",
        "RESOLUTION = (224, 224)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce2e99ea-c85f-452f-a430-760f7ddc1cd8"
      },
      "source": [
        "### Generating Class Names & Glob Pattern\n",
        "\n",
        "Load all the file paths at the DATASET_DIR to generate the class names. Also, define glob pattern to get the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rhc14C680w9L"
      },
      "outputs": [],
      "source": [
        "class_names = helpers.get_generated_class_names(DATASET_DIR, \"train\")\n",
        "\n",
        "train_glob_pattern = helpers.get_generated_glob_pattern(DATASET_DIR, \"train\")\n",
        "test_glob_pattern = helpers.get_generated_glob_pattern(DATASET_DIR, \"test\");\n",
        "val_glob_pattern = helpers.get_generated_glob_pattern(DATASET_DIR, \"val\");\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0138dc52-4ea5-4e85-a317-fe9c26d6b529"
      },
      "source": [
        "### Dataset Setup\n",
        "\n",
        "Setup the dataset with `keras_video.VideoFrameGenerator` to do the dataset extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDQDm01p0w9L"
      },
      "outputs": [],
      "source": [
        "train_dataset_generator = VideoFrameGenerator(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    classes=class_names,\n",
        "    glob_pattern=train_glob_pattern,\n",
        "    nb_channel=NB_COLOR_CHANNELS,\n",
        "    nb_frames=NB_FRAMES,\n",
        "    seed=42,\n",
        "    target_shape=RESOLUTION,\n",
        "    transformation=None,\n",
        "    use_frame_cache=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX2nLxPQ0w9L"
      },
      "outputs": [],
      "source": [
        "test_dataset_generator = VideoFrameGenerator(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    classes=class_names,\n",
        "    glob_pattern=test_glob_pattern,\n",
        "    nb_channel=NB_COLOR_CHANNELS,\n",
        "    nb_frames=NB_FRAMES,\n",
        "    seed=42,\n",
        "    target_shape=RESOLUTION,\n",
        "    transformation=None,\n",
        "    use_frame_cache=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QV80-uaq0w9L"
      },
      "outputs": [],
      "source": [
        "val_dataset_generator = VideoFrameGenerator(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    classes=class_names,\n",
        "    glob_pattern=val_glob_pattern,\n",
        "    nb_channel=NB_COLOR_CHANNELS,\n",
        "    nb_frames=NB_FRAMES,\n",
        "    seed=42,\n",
        "    target_shape=RESOLUTION,\n",
        "    transformation=None,\n",
        "    use_frame_cache=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee-Q8Nu80w9M"
      },
      "outputs": [],
      "source": [
        "input_shape = (NB_FRAMES,) + RESOLUTION + (NB_COLOR_CHANNELS,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f4555eb-20c8-475c-94e3-20539a364bfa"
      },
      "source": [
        "### Prepare `vgg16` Layer\n",
        "\n",
        "Preparing the configuration to create the `vgg16` layer to add to the created model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqiuxh0E0w9M"
      },
      "outputs": [],
      "source": [
        "vgg16_model = VGG16(\n",
        "  include_top=False,\n",
        "  input_shape=input_shape[1:],\n",
        "  weights=\"imagenet\"\n",
        ")\n",
        "\n",
        "vgg16_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11cd363f-ac76-4ce1-a56a-4e46a8ac9ab4"
      },
      "source": [
        "### Model Creation\n",
        "\n",
        "Creating `Sequential` model and add `vgg16`, `lstm` and some other layers to the created model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3dhWPUg0w9M"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(TimeDistributed(vgg16_model, input_shape=input_shape))\n",
        "model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dense(1024, activation=\"relu\"))\n",
        "model.add(Dropout(.2))\n",
        "model.add(Dense(int(len(class_names)), activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dcc6aee-aa61-4805-8b5a-65f76a78a707"
      },
      "source": [
        "### Compiling & Fitting Setup\n",
        "\n",
        "Some setup configuration for compiling and fitting the model. Defining epochs, earlystopping, checkpoint, and callbacks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qap_eVdD0w9N"
      },
      "outputs": [],
      "source": [
        "model_epochs = 25\n",
        "model_earlystopping = EarlyStopping(monitor=\"val_loss\", patience=3)\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=\"checkpoint/vgg16_lstm-{epoch:02d}-{val_loss:.2f}.h5\",\n",
        "    mode=\"min\",\n",
        "    monitor=\"val_loss\",\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "model_callbacks = [model_earlystopping, model_checkpoint]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adafba19-c904-4376-9f27-79d85cf5460e"
      },
      "source": [
        "### Model Compile\n",
        "\n",
        "Compiling model with pre-defined configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHliqHQe0w9N"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "  loss=\"categorical_crossentropy\",\n",
        "  metrics=[\"acc\"],\n",
        "  optimizer=\"adam\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a34c8472-3564-4429-84d4-48ab13632755"
      },
      "source": [
        "### Model Training/Fitting\n",
        "\n",
        "Fit the model with real dataset with defined epochs and callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeVn95yk0w9N"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "model_history = model.fit(\n",
        "    train_dataset_generator,\n",
        "    callbacks=model_callbacks,\n",
        "    epochs=model_epochs,\n",
        "    validation_data=val_dataset_generator\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "exec_time = end_time - start_time\n",
        "\n",
        "print(\"Fitting execution time : {}s\".format(exec_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e9d822e-33b9-4429-8169-56ceb8ce7dbd"
      },
      "source": [
        "### Save Model\n",
        "\n",
        "Saving model file into `model` directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsMN4wlQ0w9O"
      },
      "outputs": [],
      "source": [
        "model.save(\"model/dance/vgg16-lstm-5e.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39addeb6-7efe-43c6-b38b-fc0b8f23e865"
      },
      "source": [
        "### Acc Visualization\n",
        "\n",
        "Visualizing acc data with Matplotlib graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZUyZLzj0w9O"
      },
      "outputs": [],
      "source": [
        "helpers.get_visualized_graph(\n",
        "  plots=[model_history.history[\"acc\"], model_history.history[\"val_acc\"]],\n",
        "  title=\"Model Accuracy\",\n",
        "  x_label=\"Epoch\",\n",
        "  y_label=\"Accuracy\",\n",
        "  legend=[\"train\", \"test\"]\n",
        ").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "641f828d-52a6-4be1-bf9a-81dddfac9cd1"
      },
      "source": [
        "### Loss Visualization\n",
        "\n",
        "Visualizing loss data with Matplotlib graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM-Vm8p90w9O"
      },
      "outputs": [],
      "source": [
        "helpers.get_visualized_graph(\n",
        "  plots=[model_history.history[\"loss\"], model_history.history[\"val_loss\"]],\n",
        "  title=\"Model Loss\",\n",
        "  x_label=\"Epoch\",\n",
        "  y_label=\"Loss\",\n",
        "  legend=[\"train\", \"test\"]\n",
        ").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "482d50ed-f966-42f9-a407-3fe05d6a1455"
      },
      "source": [
        "### Export Dataframe From Model\n",
        "\n",
        "Export dataframe to `.csv` file from the model history via Pandas library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFeCE_V00w9P"
      },
      "outputs": [],
      "source": [
        "model_history_dataframe = pd.DataFrame(model_history.history)\n",
        "model_history_fpath = \"history/dance/vgg16-lstm-5e.csv\"\n",
        "\n",
        "with open(model_history_fpath, mode=\"w\") as history_file:\n",
        "    model_history_dataframe.to_csv(history_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6842666-03a7-44db-b30a-d21b5983510e"
      },
      "source": [
        "### Model Evaluation\n",
        "\n",
        "Evaluating model with test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY7BPiaP0w9P"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_dataset_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e85e757-d57d-4dbd-8945-593c3e72b615"
      },
      "source": [
        "### Populate Y Data\n",
        "\n",
        "Populating Y's `prediction` and `test` data with test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ0X338M0w9P"
      },
      "outputs": [],
      "source": [
        "y_prediction_max, y_true = helpers.get_populated_y_data(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    generator=test_dataset_generator,\n",
        "    model=model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "883998d3-0340-4b76-8cfe-30681ead035c"
      },
      "source": [
        "### Score Visualization\n",
        "\n",
        "Visualizing some of calculated model score types, like `accuracy`, `precision`, `recall`, and `f1` score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2F3PjPL0w9T"
      },
      "outputs": [],
      "source": [
        "score_accuracy, score_precision, score_recall, score_f1 = helpers.get_calculated_score(y_true, y_prediction_max)\n",
        "\n",
        "print(f\"Accuracy Score\\t: {np.round(score_accuracy, 3)}\")\n",
        "print(f\"Precision Score\\t: {np.round(score_precision, 3)}\")\n",
        "print(f\"Recall Score\\t: {np.round(score_recall, 3)}\")\n",
        "print(f\"F1 Score\\t: {np.round(score_f1, 3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fa689bf-dea3-4a90-a241-bfda48c409a6"
      },
      "source": [
        "### Classification Report Visualization\n",
        "\n",
        "Visualizing classification report of test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlNUYOzf0w9U"
      },
      "outputs": [],
      "source": [
        "test_class_names = test_dataset_generator.classes\n",
        "\n",
        "print(classification_report(\n",
        "    y_true,\n",
        "    y_prediction_max,\n",
        "    target_names=test_class_names\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88c52bbb-ea6e-47b9-b32a-27458e5792b0"
      },
      "source": [
        "### Confusion Matrix Visualization\n",
        "\n",
        "Visualizing confusion matrix with heatmap table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAN7hKKv0w9U"
      },
      "outputs": [],
      "source": [
        "confusion_matrix_result = confusion_matrix(y_true, y_prediction_max)\n",
        "\n",
        "sns.heatmap(\n",
        "    confusion_matrix_result,\n",
        "    annot=True,\n",
        "    cmap=\"Blues\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3cc50ab-f69f-4ba5-b1af-375c95a56c9a"
      },
      "source": [
        "### AUC Score Visualization\n",
        "\n",
        "Visualization of AUC score calculated with FPR and TPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-oXXGnG0w9V"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, _ = roc_curve(y_true, y_prediction_max, pos_label=6)\n",
        "score_auc = auc(fpr, tpr)\n",
        "\n",
        "print(f\"AUC Score\\t: {np.round(score_auc, 3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67e6fb24-3c5c-4a63-92dd-125159d877db"
      },
      "source": [
        "### True/False Positive Rate Visualization\n",
        "\n",
        "Visualizing `true`/`false` rate with Matplotlib graph calculated from FPR and TPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u8q8Jkv0w9V"
      },
      "outputs": [],
      "source": [
        "plt.plot(fpr, tpr, marker=\".\")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
        "\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccc9006e-33e9-4690-8563-cbe7bb4402d6"
      },
      "source": [
        "### Visualizing Checkpoint Model\n",
        "\n",
        "Visualizing all the score/calculated score from the checkpoint model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2wdwtvt0w9W"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "checkpoint_model = load_model(\"checkpoint/vgg16-lstm.h5\")\n",
        "checkpoint_model.evaluate(test_dataset_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4feea24-7170-43ba-8225-c8b58b654453"
      },
      "source": [
        "### Populate Y Data\n",
        "\n",
        "Populating checkpoint model Y's `prediction` and `test` data with test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eq_4R7fB0w9W"
      },
      "outputs": [],
      "source": [
        "y_prediction_max, y_true = helpers.get_populated_y_data(\n",
        "    batch_size=BATCH_SIZE,\n",
        "    generator=test_dataset_generator,\n",
        "    model=model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d143f10-70a6-43e6-8fae-941be3a3e9ca"
      },
      "source": [
        "### Score Visualization\n",
        "\n",
        "Visualizing some of calculated checkpoint model score types, like `accuracy`, `precision`, `recall`, and `f1` score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isU2YYOx0w9X"
      },
      "outputs": [],
      "source": [
        "score_accuracy, score_precision, score_recall, score_f1 = helpers.get_calculated_score(y_true, y_prediction_max)\n",
        "\n",
        "print(f\"Accuracy Score\\t: {np.round(score_accuracy, 3)}\")\n",
        "print(f\"Precision Score\\t: {np.round(score_precision, 3)}\")\n",
        "print(f\"Recall Score\\t: {np.round(score_recall, 3)}\")\n",
        "print(f\"F1 Score\\t: {np.round(score_f1, 3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0da6f90d-1d19-4539-a05f-2de57dd9fd29"
      },
      "source": [
        "### Classification Report Visualization\n",
        "\n",
        "Visualizing checkpoint model classification report of test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Z-W0g0e0w9Y"
      },
      "outputs": [],
      "source": [
        "test_class_names = test_dataset_generator.classes\n",
        "\n",
        "print(classification_report(\n",
        "    y_true,\n",
        "    y_prediction_max,\n",
        "    target_names=test_class_names\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ef84fa1-9e1a-40af-bd73-e5eab70e8f72"
      },
      "source": [
        "### Confusion Matrix Visualization\n",
        "\n",
        "Visualizing checkpoint model confusion matrix with heatmap table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPXKR1Q50w9Y"
      },
      "outputs": [],
      "source": [
        "confusion_matrix_result = confusion_matrix(y_true, y_prediction_max)\n",
        "\n",
        "sns.heatmap(\n",
        "    confusion_matrix_result,\n",
        "    annot=True,\n",
        "    cmap=\"Blues\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "231a5d94-09d9-4db2-a676-0ee3d43c0219"
      },
      "source": [
        "### AUC Score Visualization\n",
        "\n",
        "Visualization of checkpoint model AUC score calculated with FPR and TPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCZI8Feh0w9Z"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, _ = roc_curve(y_true, y_prediction_max, pos_label=6)\n",
        "score_auc = auc(fpr, tpr)\n",
        "\n",
        "print(f\"AUC Score\\t: {np.round(score_auc, 3)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "486f4586-8fdb-4557-bf9a-ddc855709e83"
      },
      "source": [
        "### True/False Positive Rate Visualization\n",
        "\n",
        "Visualizing checkpoint model `true`/`false` rate with Matplotlib graph calculated from FPR and TPR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfrONI7P0w9Z"
      },
      "outputs": [],
      "source": [
        "plt.plot(fpr, tpr, marker=\".\")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", linestyle=\"--\")\n",
        "\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b2527e6f53b689e62fd6e328abffb3256ca5fab4c90ca1af42ac0843cf73f556"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}